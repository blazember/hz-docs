= Capacity Planning

== Planning with the Memory

There is a HybridLog data structure for every map's every partition, plus, there is a HybridLog for every index defined for these maps. Since the HybridLog has a mandatory memory part, the configuration of the IMaps backed by Tiered Storage determine the minimum required native memory available for the system. This minimum memory footprint can be calculated with the

----
min_memory = (ts_imap_count + ts_index_count) * partition_count
             * min_hybridlog_mem
----

formula, where the variables mean the following:

- `ts_imap_count`: The number of IMaps has Tiered Storage enabled,
 - `ts_index_count`: The sum of all indices defined for the Tiered Storage IMaps,
 - `partition_count`: The partition count of the Hazelcast cluster; by default 271,
 - `min_hybridlog_mem`: Constant 4MB.

This means that having Tiered Storage enabled for a single IMap, with no index configured, and with the default partition count the minimum required memory is `(1 + 0) * 271 * 4MB = 1084MB`.

The Hazelcast cluster members validate on startup if the native memory configured for the member is greater than or equal to the minimum required memory as calculated above, and if not, the member fails to start.

##TODO: can/should we give a formula for the hash index too? It depends on the entry count.
##

NOTE: Despite that the partitions are distributed in the cluster, and therefore, a single member is not expected to store data from all partitions, in undesired conditions - such as network splits, member shutdowns - this may happen. This is the reason why Hazelcast always uses the partition count of the cluster for the above validation.

== Planning with the Disk

There are no hard minimums for the available disk capacity as the amount of data stored by Tiered Storage is not known by Hazelcast and the disk usage depends only on the data amount. There are still a few things to consider:

- The aggregated capacity of the memory and the disk has to be big enough for the data stored in the IMap.
- There are always unreachable entries on the disk.
- Compaction will get triggered at certain usage percentage of the configured capacity, therefore, the disk has to be configured bigger than the total data stored by the member.
- The bigger the disk headroom on top of the data, the more efficient the compactor is.
